{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D RECONSTRUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando FPS\n",
    "# Use -> start_time = time.time() # start time of the loop\n",
    "def CalcFPS(start_time):\n",
    "    fps = 'FPS: ' + str(int(1 / ((time.time() - start_time)/20)))\n",
    "    \n",
    "    return fps\n",
    "\n",
    "# Load previously saved data of calibration\n",
    "def LoadCalib():\n",
    "    with np.load('data_calib_left.npz') as X:\n",
    "        mtxL, distL, rvecsL, tvecsL, objpointsL, imgpointsL = [X[i] for i in ('mtxL', 'distL', 'rvecsL', 'tvecsL', 'objpointsL', 'imgpointsL')]\n",
    "    with np.load('data_calib_right.npz') as X:\n",
    "        mtxR, distR, rvecsR, tvecsR, objpointsR, imgpointsR = [X[i] for i in ('mtxR', 'distR', 'rvecsR', 'tvecsR', 'objpointsR', 'imgpointsR')]\n",
    "\n",
    "    return mtxL, distL, rvecsL, tvecsL, objpointsL, imgpointsL, mtxR, distR, rvecsR, tvecsR, objpointsR, imgpointsR\n",
    "\n",
    "# Apply Undistortion -- optional use\n",
    "def ImageUndistort(img, mtx, dist):\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\n",
    "    # Using undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image\n",
    "    x,y,w,h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    \n",
    "    return dst\n",
    "\n",
    "# Re-projection Errors -- optional use\n",
    "def ProjError(imgpoints, objpoints, rvecs, tvecs, mtx, dist):\n",
    "    tot_error = 0\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "        error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "        tot_error += error\n",
    "    \n",
    "    errors = tot_error/len(objpoints)\n",
    "    return errors\n",
    "\n",
    "# Draw xyz axes -- other option of drawing\n",
    "def DrawAxes(img, corners, rvecs, tvecs, mtx, dist):\n",
    "    axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "    \n",
    "    # project 3D points to image plane\n",
    "    imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "    \n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img\n",
    "\n",
    "# Draw Cube at axes\n",
    "def DrawCube(img, corners, rvecs, tvecs, mtx, dist):\n",
    "    axis = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0],\n",
    "                   [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])\n",
    "    \n",
    "    # project 3D points to image plane\n",
    "    imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)  \n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "\n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "\n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "\n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Set disparity parameters\n",
    "def ConfigDisparity():\n",
    "    \n",
    "    window_size = 3\n",
    "    min_disp = 16\n",
    "    num_disp = 64 #divisible by 16\n",
    "    \n",
    "    stereoL = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "                                    numDisparities = num_disp,\n",
    "                                    blockSize = window_size,\n",
    "                                    uniquenessRatio = 10,\n",
    "                                    speckleWindowSize = 100,\n",
    "                                    speckleRange = 32,\n",
    "                                    disp12MaxDiff = 5,\n",
    "                                    P1 = 8*3*window_size**2,\n",
    "                                    P2 = 32*3*window_size**2)\n",
    "    \n",
    "    # Used for the filtered image\n",
    "    stereoR=cv2.ximgproc.createRightMatcher(stereoL) # Create another stereo for right this time\n",
    "    \n",
    "    return stereoL, stereoR\n",
    "    \n",
    "# Draw epipolar lines to adjsut camera\n",
    "def DrawEpipolarLines(frameL, frameR):\n",
    "    img_h, img_w, chl = frameL.shape\n",
    "    \n",
    "    for x in range(0, int(img_h/20)):\n",
    "        cv2.line(frameL, (0,x*20), (img_w,x*20), (255,255,255), thickness=1, lineType=8, shift=0)\n",
    "        cv2.line(frameR, (0,x*20), (img_w,x*20), (255,255,255), thickness=1, lineType=8, shift=0)\n",
    "\n",
    "    return frameL, frameR\n",
    "    \n",
    "print('Functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPTH MAP FROM STEREO IMAGES\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pt_col = 6\n",
    "pt_lin = 5\n",
    "count_time = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fps = 'FPS: 30'\n",
    "x_cut = 80\n",
    "pic_count = 0\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "    \n",
    "# Open cameras\n",
    "CamR= cv2.VideoCapture(1)\n",
    "CamL= cv2.VideoCapture(0)\n",
    "\n",
    "# Load all calibration data\n",
    "mtxL, distL, rvecsL, tvecsL, objpointsL, imgpointsL, mtxR, distR, rvecsR, tvecsR, objpointsR, imgpointsR = LoadCalib()\n",
    "print('Data of calibration loaded with sucess!')\n",
    "\n",
    "if CamR.isOpened() and CamL.isOpened():\n",
    "    print('CAMERA ON')\n",
    "else:\n",
    "    print('CAMERA OFF')\n",
    "\n",
    "while(True):\n",
    "    if count_time == 0:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Read frames\n",
    "    retL, frameL= CamL.read()\n",
    "    retR, frameR= CamR.read()\n",
    "    \n",
    "    frameL_copy = frameL.copy()\n",
    "    frameR_copy = frameR.copy()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    grayL = cv2.cvtColor(frameL, cv2.COLOR_BGR2GRAY)\n",
    "    grayR = cv2.cvtColor(frameR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #grayL = cv2.GaussianBlur(grayL, (5,5), 0)\n",
    "    #grayR = cv2.GaussianBlur(grayR, (5,5), 0)\n",
    "    \n",
    "    # Undistort images\n",
    "    imgL_und = ImageUndistort(grayL, mtxL, distL)\n",
    "    imgR_und = ImageUndistort(grayR, mtxR, distR)\n",
    "    \n",
    "    # Resize images after undistorted\n",
    "    imgL_resized = cv2.resize(imgL_und, (int(grayL.shape[1]), int(grayL.shape[0])))\n",
    "    imgR_resized = cv2.resize(imgR_und, (int(grayR.shape[1]), int(grayR.shape[0])))    \n",
    "  \n",
    "    # Set disparity parameters and create matcher in both sides\n",
    "    stereo_left, stereo_right = ConfigDisparity()\n",
    "    \n",
    "    # Calcule disparity\n",
    "    disparityL = stereo_left.compute(imgL_resized, imgR_resized)\n",
    "    disparityR = stereo_right.compute(imgR_resized, imgL_resized)\n",
    "\n",
    "    # Filter parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplier = 1.0\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=stereo_left)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "    \n",
    "    # Filter disparity\n",
    "    img_filtered = wls_filter.filter(disparityL, imgL_resized, None, disparityR)\n",
    "    img_filtered = cv2.normalize(src=img_filtered, dst=img_filtered, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    img_filtered = np.uint8(img_filtered)\n",
    "    disparityL = np.uint8(disparityL)\n",
    "    disparityR = np.uint8(disparityR)\n",
    "    \n",
    "    # Apply colormap to result\n",
    "    img_colored = cv2.applyColorMap(img_filtered, cv2.COLORMAP_JET)\n",
    "       \n",
    "    # Draw epipolar lines to align cameras\n",
    "    frameL, frameR = DrawEpipolarLines(frameL, frameR)\n",
    "    \n",
    "    # Calcule FPS rate and draw\n",
    "    count_time += 1\n",
    "    if count_time == 20:\n",
    "        fps = CalcFPS(start_time)\n",
    "        count_time = 0\n",
    "    cv2.putText(frameL, fps, (10,15), font, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('disparity', img_colored)      \n",
    "    cv2.imshow('frameL',frameL)\n",
    "    cv2.imshow('frameR',frameR)\n",
    "    \n",
    "    # Take a picture with spacebar\n",
    "    if cv2.waitKey(10) & 0xFF == 32:\n",
    "        pic_count += 1\n",
    "        file_name_L = 'outputs/frameL' + str(pic_count) + '.jpg'\n",
    "        file_name_R = 'outputs/frameR' + str(pic_count) + '.jpg'\n",
    "        file_name_res = 'outputs/disparity' + str(pic_count) + '.jpg'\n",
    "        cv2.imwrite(file_name_L, frameL_copy[0:img_filtered.shape[0], x_cut:img_filtered.shape[1]])\n",
    "        cv2.imwrite(file_name_R, frameR_copy[0:img_filtered.shape[0], x_cut:img_filtered.shape[1]])\n",
    "        cv2.imwrite(file_name_res, img_filtered[0:img_filtered.shape[0], x_cut:img_filtered.shape[1]])\n",
    "        \n",
    "        plt.imshow(img_filtered[0:img_filtered.shape[0], x_cut:img_filtered.shape[1]])\n",
    "        plt.show()\n",
    "    \n",
    "    # End the Programme\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "# When everything done, release the capture\n",
    "CamR.release()\n",
    "CamL.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EPIPOLAR GEOMETRY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c,_ = img1.shape\n",
    "    #img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    #img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "def DrawAvgPoints(img1, img2, pts1, pts2):\n",
    "\n",
    "    img_center1 = img1.copy()\n",
    "    img_center2 = img2.copy()\n",
    "    \n",
    "    x_center_pts1 = (sum(pts1[:,0]) / len(pts1)).astype(int)\n",
    "    y_center_pts1 = (sum(pts1[:,1]) / len(pts1)).astype(int)\n",
    "    x_center_pts2 = (sum(pts2[:,0]) / len(pts2)).astype(int)\n",
    "    y_center_pts2 = (sum(pts2[:,1]) / len(pts2)).astype(int)\n",
    "    \n",
    "    center_pts1 = (x_center_pts1, y_center_pts1)\n",
    "    center_pts2 = (x_center_pts2, y_center_pts2)\n",
    "    \n",
    "    img_center1 = cv2.circle(img_center1, center_pts1, 5, (0,255,0), -1)\n",
    "    img_center2 = cv2.circle(img_center2, center_pts2, 5, (0,255,0), -1)\n",
    "    \n",
    "    return img_center1, img_center2, center_pts1, center_pts2\n",
    "\n",
    "print('Functions OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "\n",
    "center_pts1_arr = []\n",
    "center_pts2_arr = []\n",
    "pts1_arr = []\n",
    "pts2_arr = []\n",
    "\n",
    "images_left = []\n",
    "images_left = glob.glob('outputs/frameL*.jpg')\n",
    "\n",
    "for frame in range(0, len(images_left), 1):\n",
    "    \n",
    "    img1 = cv2.imread(images_left[0])  #queryimage # left image\n",
    "    img2 = cv2.imread(images_left[frame]) #trainimage # right image\n",
    "    print(images_left[0], ' ', images_left[frame])\n",
    "\n",
    "    img1_copy = img1.copy()\n",
    "    img2_copy = img2.copy()\n",
    "\n",
    "    #sift = cv2.SIFT()\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)\n",
    "\n",
    "    # We select only inlier points\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "\n",
    "    # Find epilines corresponding to points in right image (second image) and\n",
    "    # drawing its lines on left image\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "    lines1 = lines1.reshape(-1,3)\n",
    "    img5, img6 = drawlines(img1,img2,lines1,pts1,pts2)\n",
    "\n",
    "    # Find epilines corresponding to points in left image (first image) and\n",
    "    # drawing its lines on right image\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "    lines2 = lines2.reshape(-1,3)\n",
    "    img3, img4 = drawlines(img2,img1,lines2,pts2,pts1)\n",
    "\n",
    "    #cv2.imwrite('outputs/frameL_epipolar.jpg', img5)\n",
    "    #cv2.imwrite('outputs/frameR_epipolar.jpg', img6)\n",
    "\n",
    "    \"\"\"plt.subplot(121),plt.imshow(img5)\n",
    "    plt.subplot(122),plt.imshow(img6)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    img_center1, img_center2, center_pts1, center_pts2 = DrawAvgPoints(img1_copy, img2_copy, pts1, pts2)\n",
    "    \n",
    "    \"\"\"plt.subplot(121),plt.imshow(img_center1)\n",
    "    plt.subplot(122),plt.imshow(img_center2)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    #cv2.imwrite('outputs/frameL_center.jpg', img_center1)\n",
    "    #cv2.imwrite('outputs/frameR_center.jpg', img_center2)\n",
    "    \n",
    "    center_pts1_arr.append(list(center_pts1))\n",
    "    center_pts2_arr.append(list(center_pts2))\n",
    "    pts1_arr.append(list(pts1))\n",
    "    pts2_arr.append(list(pts2))\n",
    "    \n",
    "# Save keypoints data\n",
    "np.savez('data_keypoints', center_pts1_arr=center_pts1_arr, center_pts2_arr=center_pts2_arr, pts1_arr=pts1_arr, pts2_arr=pts2_arr)\n",
    "print('Data of keypoints saved as \"data_keypoints\"!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCENE 3D CREATE AND TRANSFORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcions OK\n"
     ]
    }
   ],
   "source": [
    "# Load previously saved data of calibration\n",
    "def LoadPts():\n",
    "    with np.load('data_keypoints.npz') as X:\n",
    "        center_pts1_arr, center_pts2_arr, pts1_arr, pts2_arr = [X[i] for i in ('center_pts1_arr', 'center_pts2_arr', 'pts1_arr', 'pts2_arr')]\n",
    "    \n",
    "    return center_pts1_arr, center_pts2_arr, pts1_arr, pts2_arr\n",
    "\n",
    "def AngleDiscover(center_pts1, center_pts2, pts1, pts2):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    angle = 0\n",
    "    center_pt1_dist = 0\n",
    "    center_pt2_dist = 0\n",
    "    \n",
    "    for i in range(0, len(pts1), 1):\n",
    "        center_pt1_dist += abs(center_pts1[0] - pts1[i][0])\n",
    "        center_pt2_dist += abs(center_pts2[0] - pts2[i][0])\n",
    "        \n",
    "    print('Diferenças totais: ', center_pt1_dist, center_pt2_dist)\n",
    "    \n",
    "    if center_pt1_dist > center_pt2_dist:\n",
    "        C = center_pt1_dist / len(pts1)\n",
    "        A = center_pt2_dist / len(pts1)\n",
    "    else:\n",
    "        A = center_pt1_dist / len(pts1)\n",
    "        C = center_pt2_dist / len(pts1)\n",
    "    \n",
    "    print('Distâncias cateto/hipotenusa: ', A,C)\n",
    "    \n",
    "    angle = math.acos(math.radians(A/C))\n",
    "    \n",
    "    print('Angulo de giro: ', angle)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def TransformMatrix3D(df_source, frame):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    depth_angle = AngleDiscover(center_pts1_arr[frame], center_pts2_arr[frame], pts1_arr[frame], pts2_arr[frame])\n",
    "    z_shift = 0\n",
    "    x_center_rotation = center_pts2_arr[frame][0]\n",
    "    x_shift = center_pts1_arr[frame][0] - center_pts2_arr[frame][0]\n",
    "    \n",
    "    #rotation_matrix = R\n",
    "    #translation_matrix = t\n",
    "    h = df_source.shape[0]\n",
    "    \n",
    "    df_rotated = df_source.copy()\n",
    "        \n",
    "    for i in range(0, h, 1):      \n",
    "        # new Z = X.tan(angle) + depth\n",
    "        df_rotated.at[i, 'z'] = (df_source.at[i, 'z'] \n",
    "                                + (math.tan(math.radians(depth_angle)) * (df_source.at[i, 'x'] - x_center_rotation)) \n",
    "                                + z_shift)\n",
    "        \n",
    "        df_rotated.at[i, 'x'] = df_source.at[i, 'x'] + x_shift\n",
    "            \n",
    "    df_source[['y','x','z']] = df_source[['y','x','z']].astype(int)\n",
    "    return df_rotated\n",
    "\n",
    "print('Funcions OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1moutputs\\frameL1.jpg\u001b[0m\n",
      "\n",
      "\u001b[1moutputs\\frameL2.jpg\u001b[0m\n",
      "Diferenças totais:  15290 15290\n",
      "Distâncias cateto/hipotenusa:  101.25827814569537 101.25827814569537\n",
      "Angulo de giro:  1.5533421480573115\n",
      "\n",
      "\u001b[1moutputs\\frameL3.jpg\u001b[0m\n",
      "Diferenças totais:  14858 14858\n",
      "Distâncias cateto/hipotenusa:  99.05333333333333 99.05333333333333\n",
      "Angulo de giro:  1.5533421480573115\n",
      "\n",
      "\u001b[1moutputs\\frameL4.jpg\u001b[0m\n",
      "Diferenças totais:  15510 15510\n",
      "Distâncias cateto/hipotenusa:  102.03947368421052 102.03947368421052\n",
      "Angulo de giro:  1.5533421480573115\n",
      "\n",
      "\u001b[1moutputs\\frameL5.jpg\u001b[0m\n",
      "Diferenças totais:  15826 15826\n",
      "Distâncias cateto/hipotenusa:  101.44871794871794 101.44871794871794\n",
      "Angulo de giro:  1.5533421480573115\n",
      "\n",
      "\n",
      "Arquivo de objeto 3D salvo em \"outputs/3D-SCENE.ply\"!\n"
     ]
    }
   ],
   "source": [
    "### CREATE 3D SCENE WITH IMAGE AND DEPTH SAVED\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pyntcloud import PyntCloud\n",
    "import glob\n",
    "\n",
    "images_left = []\n",
    "images_result = []\n",
    "images_left = glob.glob('outputs/frameL*.jpg')\n",
    "images_disparity = glob.glob('outputs/disparity*.jpg')\n",
    "\n",
    "center_pts1_arr, center_pts2_arr, pts1_arr, pts2_arr = LoadPts()\n",
    "\n",
    "data_frame = pd.DataFrame()\n",
    "\n",
    "for frame in range(0, len(images_left), 1):\n",
    "    \n",
    "    print('\\n\\033[1m' + images_left[frame] + '\\033[0m')\n",
    "    \n",
    "    # Get the colour image. Convert the RGB values to a DataFrame\n",
    "    colourImg    = Image.open(images_left[frame])\n",
    "    colourPixels = colourImg.convert(\"RGB\")\n",
    "\n",
    "    # Add the RGB values to the DataFrame\n",
    "    colourArray  = np.array(colourPixels.getdata()).reshape((colourImg.height, colourImg.width) + (3,))\n",
    "    indicesArray = np.moveaxis(np.indices((colourImg.height, colourImg.width)), 0, 2)\n",
    "    imageArray   = np.dstack((indicesArray, colourArray)).reshape((-1,5))\n",
    "    df = pd.DataFrame(imageArray, columns=[\"y\", \"x\", \"red\",\"green\",\"blue\"])\n",
    "\n",
    "    # Open the depth-map as a greyscale image. Convert it into an array of depths. Add it to the DataFrame\n",
    "    depthImg = Image.open(images_disparity[frame]).convert('L')\n",
    "    depthArray = np.array(depthImg.getdata())\n",
    "    df.insert(loc=2, column='z', value=depthArray)\n",
    "\n",
    "    # Convert it to a Point Cloud and display it\n",
    "    df[['y','x','z']] = df[['y','x','z']].astype(int)\n",
    "    df[['red','green','blue']] = df[['red','green','blue']].astype(np.uint)\n",
    "\n",
    "    \"\"\"file_name_3d = 'outputs/result3D' + str(frame+1) + '.ply'\n",
    "    cloud = PyntCloud(df)\n",
    "    cloud.to_file(file_name_3d, also_save=[\"mesh\",\"points\"],as_text=True)\"\"\"\n",
    "    \n",
    "    df = FilterDataFrame(df)\n",
    "\n",
    "    if frame > 0:\n",
    "        df_transform = TransformMatrix3D(df, frame)\n",
    "        data_frame = data_frame.append(df_transform, ignore_index=True)\n",
    "    else:\n",
    "        data_frame = data_frame.append(df, ignore_index=True)\n",
    "        \n",
    "cloud = PyntCloud(data_frame)\n",
    "cloud.to_file(\"outputs/3D-SCENE.ply\", also_save=[\"mesh\",\"points\"],as_text=True)\n",
    "print('\\n\\nArquivo de objeto 3D salvo em \"outputs/3D-SCENE.ply\"!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterDataFrame(df_filter):\n",
    "    for i in range(0, len(df_filter), 1):\n",
    "        if df_filter.at[i, 'z'] < 50:\n",
    "            df_filter.drop([i])\n",
    "    \n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW THE 3D SCENE WITH PPTK\n",
    "import pptk\n",
    "import numpy as np\n",
    "import plyfile\n",
    "\n",
    "data = plyfile.PlyData.read('outputs/3D-SCENE.ply')['vertex']\n",
    "\n",
    "xyz = np.c_[data['y'], data['x'], data['z']]\n",
    "rgb = np.c_[data['red'], data['green'], data['blue']]\n",
    "\n",
    "v = pptk.viewer(xyz)\n",
    "v.set(point_size = 0.3)\n",
    "v.attributes(rgb / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
